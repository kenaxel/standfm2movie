import { NextRequest, NextResponse } from 'next/server'
import { VideoGenerationRequest, VideoGenerationResult, VideoAsset, TranscriptSegment } from '@/types'
import fs from 'fs'
import path from 'path'
import os from 'os'
// FFmpegã‚’ä½¿ç”¨ã—ãŸå‹•ç”»ç”Ÿæˆã®ãŸã‚ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import ffmpeg from 'fluent-ffmpeg'
import OpenAI from 'openai'
import { searchVideos } from '@/lib/pexels'
import { searchPhotos } from '@/lib/unsplash'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

// æ–‡å­—èµ·ã“ã—çµæœã‚’åˆ†æã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã‚·ãƒ¼ãƒ³ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
async function analyzeTranscriptForKeywords(transcript: TranscriptSegment[]): Promise<{
  keywords: string[]
  scenes: Array<{
    startTime: number
    endTime: number
    keywords: string[]
    emotion: string
    visualConcepts: string[]
  }>
}> {
  try {
    const fullText = transcript.map(segment => segment.text).join(' ')
    
    const prompt = `ä»¥ä¸‹ã®éŸ³å£°æ–‡å­—èµ·ã“ã—çµæœã‚’åˆ†æã—ã¦ã€å‹•ç”»ã«é©ã—ãŸç”»åƒãƒ»å‹•ç”»ç´ æã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã‚·ãƒ¼ãƒ³æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

æ–‡å­—èµ·ã“ã—å†…å®¹:
${fullText}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{
  "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", ...],
  "scenes": [
    {
      "startTime": 0,
      "endTime": 30,
      "keywords": ["ã‚·ãƒ¼ãƒ³å›ºæœ‰ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"],
      "emotion": "æ„Ÿæƒ…ï¼ˆhappy, sad, excited, calm, serious ãªã©ï¼‰",
      "visualConcepts": ["è¦–è¦šçš„ã‚³ãƒ³ã‚»ãƒ—ãƒˆï¼ˆnature, business, technology, people ãªã©ï¼‰"]
    }
  ]
}

æ³¨æ„:
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯è‹±èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆç”»åƒæ¤œç´¢APIç”¨ï¼‰
- æ„Ÿæƒ…ã¯è‹±èªã®å˜èªã§è¡¨ç¾ã—ã¦ãã ã•ã„
- è¦–è¦šçš„ã‚³ãƒ³ã‚»ãƒ—ãƒˆã¯å…·ä½“çš„ã§æ¤œç´¢ã—ã‚„ã™ã„ã‚‚ã®ã«ã—ã¦ãã ã•ã„
- ã‚·ãƒ¼ãƒ³ã¯30ç§’ç¨‹åº¦ã®é•·ã•ã«åˆ†å‰²ã—ã¦ãã ã•ã„`

    const response = await openai.chat.completions.create({
      model: 'gpt-4',
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.3
    })

    const analysisResult = JSON.parse(response.choices[0].message.content || '{"keywords": [], "scenes": []}')
    console.log('æ–‡å­—èµ·ã“ã—åˆ†æçµæœ:', analysisResult)
    
    return analysisResult
  } catch (error) {
    console.error('æ–‡å­—èµ·ã“ã—åˆ†æã‚¨ãƒ©ãƒ¼:', error)
    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿”ã™
    return {
      keywords: ['business', 'presentation', 'meeting'],
      scenes: [{
        startTime: 0,
        endTime: transcript.reduce((max, segment) => Math.max(max, segment.endTime), 60),
        keywords: ['business'],
        emotion: 'neutral',
        visualConcepts: ['office', 'professional']
      }]
    }
  }
}

// ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ç”»åƒãƒ»å‹•ç”»ç´ æã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°
async function searchMediaAssets(keywords: string[], scenes: any[]): Promise<VideoAsset[]> {
  try {
    const assets: VideoAsset[] = []
    
    // å„ã‚·ãƒ¼ãƒ³ã«å¯¾ã—ã¦ç´ æã‚’æ¤œç´¢
    for (const scene of scenes) {
      const sceneKeywords = [...scene.keywords, ...scene.visualConcepts]
      const searchQuery = sceneKeywords.join(' ')
      
      console.log(`ã‚·ãƒ¼ãƒ³ ${scene.startTime}-${scene.endTime}s ã®æ¤œç´¢ã‚¯ã‚¨ãƒª:`, searchQuery)
      
      try {
        // Pexelsã‹ã‚‰å‹•ç”»ã‚’æ¤œç´¢ï¼ˆæ¤œç´¢æ•°ã‚’å¢—ã‚„ã™ï¼‰
        const videos = await searchVideos(searchQuery, 5)
        
        // å„å‹•ç”»ã«ç•°ãªã‚‹é–‹å§‹æ™‚é–“ã‚’å‰²ã‚Šå½“ã¦ã‚‹
        const sceneDuration = scene.endTime - scene.startTime
        const videoDuration = sceneDuration / Math.max(videos.length, 1)
        
        videos.forEach((video, index) => {
          const videoStartTime = scene.startTime + (index * videoDuration)
          const videoEndTime = Math.min(videoStartTime + (video.duration || 5), scene.endTime)
          
          assets.push({
            type: 'video',
            url: video.url,
            duration: videoEndTime - videoStartTime,
            startTime: videoStartTime,
            endTime: videoEndTime
          })
        })
        
        // Unsplashã‹ã‚‰ç”»åƒã‚’æ¤œç´¢ï¼ˆæ¤œç´¢æ•°ã‚’å¢—ã‚„ã™ï¼‰
        const images = await searchPhotos(searchQuery, 8)
        
        // å„ç”»åƒã«ç•°ãªã‚‹é–‹å§‹æ™‚é–“ã‚’å‰²ã‚Šå½“ã¦ã‚‹
        const imageDuration = 3 // å„ç”»åƒã®è¡¨ç¤ºæ™‚é–“ã‚’çŸ­ã
        
        images.forEach((image, index) => {
          // ã‚·ãƒ¼ãƒ³å†…ã§å‡ç­‰ã«åˆ†æ•£
          const imageStartTime = scene.startTime + (index * (sceneDuration / Math.max(images.length, 1)))
          const imageEndTime = Math.min(imageStartTime + imageDuration, scene.endTime)
          
          if (imageStartTime < imageEndTime) {
            assets.push({
              type: 'image',
              url: image.url,
              duration: imageEndTime - imageStartTime,
              startTime: imageStartTime,
              endTime: imageEndTime
            })
          }
        })
        
      } catch (searchError) {
        console.error(`ã‚·ãƒ¼ãƒ³ ${scene.startTime}-${scene.endTime}s ã®æ¤œç´¢ã‚¨ãƒ©ãƒ¼:`, searchError)
        
        // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”»åƒã‚’è¿½åŠ 
        assets.push({
          type: 'image',
          url: 'https://via.placeholder.com/1280x720/0066cc/ffffff?text=Scene+' + Math.floor(scene.startTime),
          duration: scene.endTime - scene.startTime,
          startTime: scene.startTime,
          endTime: scene.endTime
        })
      }
    }
    
    console.log(`æ¤œç´¢å®Œäº†: ${assets.length}å€‹ã®ç´ æã‚’å–å¾—`)
    return assets
    
  } catch (error) {
    console.error('ç´ ææ¤œç´¢ã‚¨ãƒ©ãƒ¼:', error)
    return []
  }
}

// éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’å–å¾—ã™ã‚‹é–¢æ•°
async function getAudioDuration(audioPath: string): Promise<number> {
  return new Promise((resolve, reject) => {
    const ffmpeg = require('fluent-ffmpeg')
    
    ffmpeg.ffprobe(audioPath, (err: any, metadata: any) => {
      if (err) {
        console.error('FFprobe error:', err)
        reject(err)
        return
      }
      
      const duration = metadata.format.duration
      console.log('Audio duration detected:', duration, 'seconds')
      resolve(duration)
    })
  })
}

// éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†é–¢æ•°
async function processAudioFile(audioInput: any, tempDir: string): Promise<string | null> {
  if (!audioInput) return null
  
  try {
    let audioPath: string | null = null
    
    // æ–‡å­—åˆ—ã®å ´åˆã¯éŸ³å£°åˆæˆã‚’è¡Œã†
    if (typeof audioInput === 'string') {
      console.log('Text input detected, generating speech...')
      audioPath = path.join(tempDir, 'synthesized_audio.mp3')
      
      // OpenAI Text-to-Speech APIã‚’ä½¿ç”¨ã—ãŸéŸ³å£°åˆæˆ
      try {
        const mp3 = await openai.audio.speech.create({
          model: "tts-1",
          voice: "alloy",
          input: audioInput,
        });
        
        const buffer = Buffer.from(await mp3.arrayBuffer());
        await fs.promises.writeFile(audioPath, buffer);
        console.log('Synthesized audio created with OpenAI TTS:', audioPath)
        return audioPath
      } catch (ttsError) {
        console.error('OpenAI TTS failed, falling back to silent audio:', ttsError)
        
        // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç„¡éŸ³ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        return new Promise((resolve, reject) => {
          // ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã«åŸºã¥ã„ã¦éŸ³å£°ã®é•·ã•ã‚’è¨ˆç®—ï¼ˆ1æ–‡å­—ã‚ãŸã‚Š0.1ç§’ï¼‰
          const duration = Math.max(10, Math.min(300, audioInput.length * 0.1)) // 10ç§’ã€œ300ç§’
          
          ffmpeg()
            .input(`sine=frequency=440:duration=${duration}`)
            .inputOptions(['-f', 'lavfi'])
            .audioCodec('mp3')
            .audioFrequency(44100)
            .audioChannels(2)
            .output(audioPath)
            .on('end', () => {
              console.log('Fallback synthesized audio created:', audioPath)
              resolve(audioPath)
            })
            .on('error', (err: Error) => {
              console.error('FFmpeg error:', err)
              resolve(null)
            })
            .run()
        })
      }
    } else if (audioInput.type === 'tempFile' && audioInput.path) {
      // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
      const sourcePath = path.join(process.cwd(), 'public', audioInput.path.replace('/api/audio/', 'audio/'))
      if (fs.existsSync(sourcePath)) {
        audioPath = path.join(tempDir, `audio_${Date.now()}.mp3`)
        await fs.promises.copyFile(sourcePath, audioPath)
        console.log('Temp audio file copied:', audioPath)
        return audioPath
      } else {
        console.error('Temp audio file not found:', sourcePath)
        return null
      }
    } else if (audioInput.type === 'file' && audioInput.data) {
      // Base64ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
      const audioBuffer = Buffer.from(audioInput.data, 'base64')
      const timestamp = Date.now()
      const randomId = Math.random().toString(36).substring(2, 15)
      audioPath = path.join(tempDir, `audio_${timestamp}_${randomId}.${audioInput.format || 'mp3'}`)
      await fs.promises.writeFile(audioPath, audioBuffer)
      console.log('Audio file saved with unique name:', audioPath)
    } else if (audioInput.type === 'url' && audioInput.source) {
      // URLã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
      const timestamp = Date.now()
      const randomId = Math.random().toString(36).substring(2, 15)
      audioPath = path.join(tempDir, `audio_${timestamp}_${randomId}.mp3`)
      console.log('Audio URL provided:', audioInput.source, 'Target file:', audioPath)
      
      try {
        let audioUrl = audioInput.source
        
        // éå»ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
        if (audioUrl.startsWith('/api/audio/') || audioUrl.includes('/api/audio/')) {
          console.log('éå»ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«URLã‚’æ¤œå‡º:', audioUrl)
          
          // URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º
          const fileName = audioUrl.split('/').pop();
          if (!fileName) {
            throw new Error('Invalid audio file URL');
          }
          
          // å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
          const storedFilePath = path.join(process.cwd(), 'public', 'audio', fileName);
          
          // ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
          if (fs.existsSync(storedFilePath)) {
            console.log('éå»ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:', storedFilePath);
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
            await fs.promises.copyFile(storedFilePath, audioPath);
            return audioPath;
          } else {
            console.log('éå»ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:', storedFilePath);
            // ä»£æ›¿URLã‚’è©¦ã™
            const alternativeUrl = `${process.env.NEXT_PUBLIC_API_URL || ''}${audioUrl}`;
            console.log('ä»£æ›¿URLã‚’è©¦ã¿ã¾ã™:', alternativeUrl);
            audioUrl = alternativeUrl;
          }
        }
        
        // Stand.FMã®URLã®å ´åˆã€å®Ÿéš›ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«URLã‚’å–å¾—
        if (audioUrl.includes('stand.fm')) {
          console.log('Stand.FM URL detected, extracting audio URL...')
          
          try {
            // Stand.FMã®APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è©¦ã™
            const episodeId = audioUrl.match(/episodes\/([a-f0-9]+)/)?.[1]
            if (episodeId) {
              console.log('Episode ID found:', episodeId)
              
              // Stand.FM APIã‚’è©¦ã™
              const apiUrl = `https://stand.fm/api/episodes/${episodeId}`
              const apiResponse = await fetch(apiUrl)
              if (apiResponse.ok) {
                const apiData = await apiResponse.json()
                if (apiData.audio_url) {
                  audioUrl = apiData.audio_url
                  console.log('Audio URL from API:', audioUrl)
                } else if (apiData.episode && apiData.episode.audio_url) {
                  audioUrl = apiData.episode.audio_url
                  console.log('Audio URL from episode data:', audioUrl)
                }
              }
            }
            
            // APIã§å–å¾—ã§ããªã„å ´åˆã¯HTMLãƒšãƒ¼ã‚¸ã‹ã‚‰æŠ½å‡º
            if (audioUrl.includes('stand.fm')) {
              const pageResponse = await fetch(audioUrl)
              const pageHtml = await pageResponse.text()
              
              // è¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™
              const patterns = [
                /"audio_url"\s*:\s*"([^"]+)"/,
                /"audioUrl"\s*:\s*"([^"]+)"/,
                /"src"\s*:\s*"([^"]*\.mp3[^"]*)"/,
                /https:\/\/[^"\s]*\.mp3/g,
                /https:\/\/[^"\s]*audio[^"\s]*\.(mp3|m4a)/g,
                /__NEXT_DATA__[^<]*"audio_url":"([^"]+)"/,
                /window\.__INITIAL_STATE__[^<]*"audio_url":"([^"]+)"/
              ]
              
              for (const pattern of patterns) {
                const match = pageHtml.match(pattern)
                if (match && match[1]) {
                  audioUrl = match[1]
                  console.log('Audio URL extracted with pattern:', audioUrl)
                  break
                } else if (match && match[0] && match[0].includes('.mp3')) {
                  audioUrl = match[0]
                  console.log('Direct MP3 URL found:', audioUrl)
                  break
                }
              }
              
              // å…ƒã®Stand.FMãƒšãƒ¼ã‚¸URLã¨åŒã˜ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆéŸ³å£°URLãŒæŠ½å‡ºã§ãã¦ã„ãªã„å ´åˆï¼‰
              if (audioUrl === audioInput.source) {
                console.log('Could not extract audio URL from Stand.FM page')
                console.log('Page HTML length:', pageHtml.length)
                // HTMLã®ä¸€éƒ¨ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                const htmlSnippet = pageHtml.substring(0, 1000)
                console.log('HTML snippet:', htmlSnippet)
                return null
              }
            }
          } catch (extractError) {
            console.error('Error extracting Stand.FM audio URL:', extractError)
            return null
          }
        }
        
        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å›é¿ã™ã‚‹ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        if (!audioUrl.includes('?')) {
          audioUrl = `${audioUrl}?t=${Date.now()}`;
        } else {
          audioUrl = `${audioUrl}&t=${Date.now()}`;
        }
        
        const response = await fetch(audioUrl)
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`)
        }
        const audioBuffer = await response.arrayBuffer()
        await fs.promises.writeFile(audioPath, Buffer.from(audioBuffer))
        console.log('Audio downloaded and saved:', audioPath)
      } catch (downloadError) {
        console.error('Failed to download audio from URL:', downloadError)
        // URLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆã¯ã€éŸ³å£°ãªã—ã§ç¶šè¡Œ
        return null
      }
    }
    
    return audioPath
  } catch (error) {
    console.error('Audio processing error:', error)
    return null
  }
}

// ç´ æã‚’ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«é…ç½®ã™ã‚‹é–¢æ•°
async function arrangeAssetsOnTimeline(assets: VideoAsset[], totalDuration: number): Promise<{
  timeline: Array<{
    asset: VideoAsset
    startTime: number
    endTime: number
    transitionType: 'fade' | 'slide' | 'zoom'
  }>
  overlayAssets: VideoAsset[]
}> {
  try {
    const timeline: Array<{
      asset: VideoAsset
      startTime: number
      endTime: number
      transitionType: 'fade' | 'slide' | 'zoom'
    }> = []
    
    const overlayAssets: VideoAsset[] = []
    
    // ç´ æã‚’æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
    const sortedAssets = assets.sort((a, b) => a.startTime - b.startTime)
    
    let currentTime = 0
    
    for (const asset of sortedAssets) {
      // ç´ æã®é…ç½®æ™‚é–“ã‚’èª¿æ•´
      const startTime = Math.max(currentTime, asset.startTime)
      const duration = Math.min(asset.duration, asset.endTime - asset.startTime)
      const endTime = startTime + duration
      
      // ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«è¿½åŠ 
      timeline.push({
        asset,
        startTime,
        endTime,
        transitionType: getTransitionType(asset.type)
      })
      
      currentTime = endTime
      
      // ç·æ™‚é–“ã‚’è¶…ãˆãªã„ã‚ˆã†ã«ãƒã‚§ãƒƒã‚¯
      if (currentTime >= totalDuration) {
        break
      }
    }
    
    // æ™‚é–“ã®éš™é–“ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã®ãƒ•ã‚£ãƒ©ãƒ¼ç´ æã‚’è¿½åŠ 
    const filledTimeline = await fillTimelineGaps(timeline, totalDuration)
    
    console.log(`ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³é…ç½®å®Œäº†: ${filledTimeline.length}å€‹ã®ç´ æã‚’é…ç½®`)
    
    return {
      timeline: filledTimeline,
      overlayAssets
    }
    
  } catch (error) {
    console.error('ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³é…ç½®ã‚¨ãƒ©ãƒ¼:', error)
    return { timeline: [], overlayAssets: [] }
  }
}

// ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã‚’æ±ºå®šã™ã‚‹é–¢æ•°
function getTransitionType(assetType: 'image' | 'video'): 'fade' | 'slide' | 'zoom' {
  const transitions: Array<'fade' | 'slide' | 'zoom'> = ['fade', 'slide', 'zoom']
  return transitions[Math.floor(Math.random() * transitions.length)]
}

// ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®éš™é–“ã‚’åŸ‹ã‚ã‚‹é–¢æ•°
async function fillTimelineGaps(timeline: any[], totalDuration: number): Promise<any[]> {
  const filledTimeline = [...timeline]
  
  // æœ€åˆã®ç´ æã®å‰ã«éš™é–“ãŒã‚ã‚‹å ´åˆ
  if (timeline.length > 0 && timeline[0].startTime > 0) {
    filledTimeline.unshift({
      asset: {
        type: 'image',
        url: 'https://via.placeholder.com/1920x1080/4f46e5/ffffff?text=Opening',
        duration: timeline[0].startTime,
        startTime: 0,
        endTime: timeline[0].startTime
      },
      startTime: 0,
      endTime: timeline[0].startTime,
      transitionType: 'fade'
    })
  }
  
  // ç´ æé–“ã®éš™é–“ã‚’åŸ‹ã‚ã‚‹
  for (let i = 0; i < timeline.length - 1; i++) {
    const currentEnd = timeline[i].endTime
    const nextStart = timeline[i + 1].startTime
    
    if (nextStart > currentEnd) {
      const gapDuration = nextStart - currentEnd
      filledTimeline.splice(i + 1, 0, {
        asset: {
          type: 'image',
          url: `https://via.placeholder.com/1920x1080/6366f1/ffffff?text=Transition+${i + 1}`,
          duration: gapDuration,
          startTime: currentEnd,
          endTime: nextStart
        },
        startTime: currentEnd,
        endTime: nextStart,
        transitionType: 'fade'
      })
    }
  }
  
  // æœ€å¾Œã®ç´ æã®å¾Œã«éš™é–“ãŒã‚ã‚‹å ´åˆ
  const lastAsset = timeline[timeline.length - 1]
  if (lastAsset && lastAsset.endTime < totalDuration) {
    filledTimeline.push({
      asset: {
        type: 'image',
        url: 'https://via.placeholder.com/1920x1080/8b5cf6/ffffff?text=Ending',
        duration: totalDuration - lastAsset.endTime,
        startTime: lastAsset.endTime,
        endTime: totalDuration
      },
      startTime: lastAsset.endTime,
      endTime: totalDuration,
      transitionType: 'fade'
    })
  }
  
  return filledTimeline
}

// ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ™ãƒ¼ã‚¹ã®å‹•ç”»ç”Ÿæˆé–¢æ•°
async function generateTimelineBasedVideo({
  timeline,
  audioPath,
  outputPath,
  settings,
  tempDir
}: {
  timeline: any[]
  audioPath: string | null
  outputPath: string
  settings: any
  tempDir: string
}): Promise<string> {
  try {
    console.log(`ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å‹•ç”»ç”Ÿæˆ: ${timeline.length}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ`)
    
    // ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
    const sortedTimeline = [...timeline].sort((a, b) => a.startTime - b.startTime);
    
    // é‡è¤‡ã™ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ï¼ˆåŒã˜æ™‚é–“å¸¯ã«è¤‡æ•°ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆï¼‰
    const uniqueTimeline: any[] = [];
    let lastEndTime = 0;
    
    for (const segment of sortedTimeline) {
      // å‰ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨é‡è¤‡ã—ãªã„éƒ¨åˆ†ã ã‘ã‚’ä½¿ç”¨
      if (segment.startTime >= lastEndTime) {
        uniqueTimeline.push(segment);
        lastEndTime = segment.endTime;
      } else if (segment.endTime > lastEndTime) {
        // éƒ¨åˆ†çš„ã«é‡è¤‡ã™ã‚‹å ´åˆã¯ã€é‡è¤‡ã—ãªã„éƒ¨åˆ†ã ã‘ã‚’ä½¿ç”¨
        const adjustedSegment = {
          ...segment,
          startTime: lastEndTime,
        };
        uniqueTimeline.push(adjustedSegment);
        lastEndTime = segment.endTime;
      }
      // å®Œå…¨ã«é‡è¤‡ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    }
    
    console.log(`é‡è¤‡é™¤å»å¾Œã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³: ${uniqueTimeline.length}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ`);
    
    // å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç”¨ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
    const segmentPaths: string[] = []
    
    for (let i = 0; i < uniqueTimeline.length; i++) {
      const segment = uniqueTimeline[i]
      const segmentPath = path.join(tempDir, `segment_${i}.mp4`)
      
      console.log(`ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ${i + 1}/${uniqueTimeline.length} ç”Ÿæˆä¸­:`, segment.asset.url)
      
      // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‹•ç”»ã‚’ç”Ÿæˆ
      await generateSegmentVideo({
        asset: segment.asset,
        startTime: segment.startTime,
        endTime: segment.endTime,
        transitionType: segment.transitionType,
        outputPath: segmentPath,
        settings,
        tempDir
      })
      
      segmentPaths.push(segmentPath)
    }
    
    // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµåˆ
    console.log('ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµåˆé–‹å§‹')
    await concatenateSegments(segmentPaths, outputPath, audioPath, settings)
    
    console.log('ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å‹•ç”»ç”Ÿæˆå®Œäº†')
    return outputPath
    
  } catch (error) {
    console.error('ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å‹•ç”»ç”Ÿæˆã‚¨ãƒ©ãƒ¼:', error)
    throw error
  }
}

// å€‹åˆ¥ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‹•ç”»ç”Ÿæˆé–¢æ•°
async function generateSegmentVideo({
  asset,
  startTime,
  endTime,
  transitionType,
  outputPath,
  settings,
  tempDir
}: {
  asset: VideoAsset
  startTime: number
  endTime: number
  transitionType: string
  outputPath: string
  settings: any
  tempDir: string
}): Promise<void> {
  return new Promise((resolve, reject) => {
    const duration = endTime - startTime
    
    let ffmpegCommand = ffmpeg()
    
    if (asset.type === 'image') {
      // ç”»åƒã®å ´åˆ
      ffmpegCommand
        .input(asset.url)
        .inputOptions(['-loop 1', '-t', duration.toString()])
        .videoFilters([
          `scale=${settings.resolution?.width || 1920}:${settings.resolution?.height || 1080}:force_original_aspect_ratio=decrease`,
          `pad=${settings.resolution?.width || 1920}:${settings.resolution?.height || 1080}:(ow-iw)/2:(oh-ih)/2`,
          getTransitionFilter(transitionType, duration)
        ])
    } else {
      // å‹•ç”»ã®å ´åˆ
      ffmpegCommand
        .input(asset.url)
        .inputOptions(['-t', duration.toString()])
        .videoFilters([
          `scale=${settings.resolution?.width || 1920}:${settings.resolution?.height || 1080}:force_original_aspect_ratio=decrease`,
          `pad=${settings.resolution?.width || 1920}:${settings.resolution?.height || 1080}:(ow-iw)/2:(oh-ih)/2`,
          getTransitionFilter(transitionType, duration)
        ])
    }
    
    ffmpegCommand
      .videoCodec('libx264')
      .fps(settings.fps || 30)
      .outputOptions(['-pix_fmt yuv420p', '-preset fast', '-crf 28'])
      .output(outputPath)
      .on('end', () => resolve())
      .on('error', (err) => reject(err))
      .run()
  })
}

// ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å–å¾—ã™ã‚‹é–¢æ•°
function getTransitionFilter(transitionType: string, duration: number): string {
  switch (transitionType) {
    case 'fade':
      return `fade=in:0:30,fade=out:${Math.max(0, duration * 30 - 30)}:30`
    case 'slide':
      return `slide=direction=right:duration=1`
    case 'zoom':
      return `zoompan=z='1+0.002*on':d=1`
    default:
      return `fade=in:0:15,fade=out:${Math.max(0, duration * 30 - 15)}:15`
  }
}

// ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµåˆé–¢æ•°
async function concatenateSegments(
  segmentPaths: string[],
  outputPath: string,
  audioPath: string | null,
  settings: any
): Promise<void> {
  return new Promise((resolve, reject) => {
    const ffmpegCommand = ffmpeg()
    
    // å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å…¥åŠ›ã¨ã—ã¦è¿½åŠ 
    segmentPaths.forEach(segmentPath => {
      ffmpegCommand.input(segmentPath)
    })
    
    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
    if (audioPath && fs.existsSync(audioPath)) {
      ffmpegCommand.input(audioPath)
    }
    
    // ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰
    const filterComplex = segmentPaths.map((_, index) => `[${index}:v]`).join('') + `concat=n=${segmentPaths.length}:v=1:a=0[outv]`
    
    ffmpegCommand
      .complexFilter(filterComplex)
      .outputOptions(['-map [outv]'])
    
    // éŸ³å£°ãƒãƒƒãƒ”ãƒ³ã‚°
    if (audioPath && fs.existsSync(audioPath)) {
      ffmpegCommand.outputOptions([`-map ${segmentPaths.length}:a`, '-shortest'])
    }
    
    ffmpegCommand
      .videoCodec('libx264')
      .audioCodec('aac')
      .outputOptions(['-pix_fmt yuv420p', '-preset fast', '-crf 28'])
      .output(outputPath)
      .on('start', (commandLine) => {
        console.log('çµåˆã‚³ãƒãƒ³ãƒ‰:', commandLine)
      })
      .on('progress', (progress) => {
        console.log('çµåˆé€²è¡ŒçŠ¶æ³:', progress.percent + '%')
      })
      .on('end', () => {
        console.log('ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµåˆå®Œäº†')
        resolve()
      })
      .on('error', (err) => {
        console.error('çµåˆã‚¨ãƒ©ãƒ¼:', err)
        reject(err)
      })
      .run()
  })
}

// éŸ³å£°ã®æ–‡å­—èµ·ã“ã—é–¢æ•°ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
async function transcribeAudioWithTimestamps(audioPath: string): Promise<TranscriptSegment[]> {
  try {
    console.log('OpenAI Whisper APIã§æ–‡å­—èµ·ã“ã—é–‹å§‹:', audioPath)
    
    // OpenAI SDKã‚’ä½¿ç”¨ã—ã¦æ–‡å­—èµ·ã“ã—
    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(audioPath),
      model: 'whisper-1',
      response_format: 'verbose_json',
      timestamp_granularities: ['segment']
    })
    
    console.log('Whisper APIçµæœ:', transcription)
    
    // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›
    const segments: TranscriptSegment[] = []
    if (transcription.segments && Array.isArray(transcription.segments)) {
      for (const segment of transcription.segments) {
        // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ãªã„å ´åˆã®ã¿è¿½åŠ 
        const trimmedText = segment.text.trim()
        if (trimmedText) {
          segments.push({
            text: trimmedText,
            startTime: segment.start,
            endTime: segment.end
          })
        }
      }
    } else if (transcription.text) {
      // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒãªã„å ´åˆã¯æ–‡ã‚’åˆ†å‰²ã—ã¦è¤‡æ•°ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
      const text = transcription.text.trim();
      
      // æ—¥æœ¬èªã®å ´åˆã¯å¥èª­ç‚¹ã§åˆ†å‰²
      const isJapanese = /[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]/.test(text);
      let sentences = [];
      
      if (isJapanese) {
        sentences = text.split(/[ã€‚.!?ï¼ï¼Ÿ]/).filter(s => s.trim());
      } else {
        // è‹±èªã®å ´åˆã¯ãƒ”ãƒªã‚ªãƒ‰ãªã©ã§åˆ†å‰²
        sentences = text.split(/[.!?]/).filter(s => s.trim());
      }
      
      // éŸ³å£°ã®é•·ã•ã‚’æ¨å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ60ç§’ï¼‰
      let audioDuration = 60;
      try {
        audioDuration = await getAudioDuration(audioPath);
      } catch (err) {
        console.log('éŸ³å£°é•·ã®å–å¾—ã«å¤±æ•—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨:', err);
      }
      
      // å„æ–‡ã«å‡ç­‰ã«æ™‚é–“ã‚’å‰²ã‚Šå½“ã¦
      const segmentDuration = audioDuration / Math.max(sentences.length, 1);
      
      sentences.forEach((sentence, index) => {
        if (sentence.trim()) {
          segments.push({
            text: sentence.trim(),
            startTime: index * segmentDuration,
            endTime: (index + 1) * segmentDuration
          });
        }
      });
    }
    
    console.log('æ–‡å­—èµ·ã“ã—å®Œäº†:', segments.length, 'å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ')
    return segments
    
  } catch (error) {
    console.error('æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼:', error)
    // ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã®é…åˆ—ã‚’è¿”ã™
    return []
  }
}

// éŸ³å£°ã‚’å­—å¹•ã¨ã—ã¦è¡¨ç¤ºã™ã‚‹å‹•ç”»ç”Ÿæˆé–¢æ•°
async function generateSubtitleVideo({
  audioPath,
  audioInput,
  transcript,
  settings,
  tempDir,
  timeline,
  audioDuration,
  outputPath
}: {
  audioPath: string
  audioInput: string
  transcript: TranscriptSegment[]
  settings: any
  tempDir: string
  timeline?: any
  audioDuration: number
  outputPath?: string
}): Promise<string> {
  // å‡ºåŠ›ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
  const finalOutputPath = outputPath || path.join(tempDir, `output_${Date.now()}.mp4`)
  
  console.log('Generating video with audio and subtitles')
  
  try {
    // å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆSRTå½¢å¼ï¼‰ã‚’ç”Ÿæˆ
    const timestamp = Date.now()
    const subtitlePath = path.join(tempDir, `subtitles_${timestamp}.srt`)
    let srtContent = ''
    
    console.log('å­—å¹•ç”Ÿæˆ - transcript:', transcript ? transcript.length : 'null', 'å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ')
    console.log('transcriptè©³ç´°:', transcript)
    if (transcript && transcript.length > 0) {
      // æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­—å¹•ã‚’ç”Ÿæˆ
      console.log('transcriptã‹ã‚‰å­—å¹•ã‚’ç”Ÿæˆ:', transcript)
      
      // å­—å¹•ã®é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ã€çŸ­ã™ãã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµåˆ
      const minSegmentDuration = 1.0; // æœ€å°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·ï¼ˆç§’ï¼‰
      const processedTranscript: TranscriptSegment[] = [];
      
      // å­—å¹•ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’èª¿æ•´ã™ã‚‹ãŸã‚ã®å‡¦ç†
      // 1. ã¾ãšå…¨ä½“ã®æ™‚é–“ã‚’ç¢ºèª
      const totalTranscriptDuration = transcript.reduce((max, segment) => 
        Math.max(max, segment.endTime), 0);
      
      // 2. éŸ³å£°ã®é•·ã•ã¨æ–‡å­—èµ·ã“ã—ã®é•·ã•ãŒå¤§ããç•°ãªã‚‹å ´åˆã¯èª¿æ•´
      const scaleFactor = totalTranscriptDuration > 0 ? 
        audioDuration / totalTranscriptDuration : 1;
      
      // 3. ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆ
      const scaledTranscript = transcript.map(segment => ({
        ...segment,
        startTime: segment.startTime * scaleFactor,
        endTime: segment.endTime * scaleFactor
      }));
      
      let currentSegment: TranscriptSegment | null = null;
      
      scaledTranscript.forEach((segment, index) => {
        // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®é•·ã•ã‚’è¨ˆç®—
        const segmentDuration = segment.endTime - segment.startTime;
        
        if (!currentSegment) {
          currentSegment = { ...segment };
        } else if (segmentDuration < minSegmentDuration || 
                  (segment.startTime - currentSegment.endTime) < 0.3) {
          // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒçŸ­ã™ãã‚‹ã€ã¾ãŸã¯å‰ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã®é–“éš”ãŒçŸ­ã™ãã‚‹å ´åˆã¯çµåˆ
          currentSegment.text += ' ' + segment.text;
          currentSegment.endTime = segment.endTime;
        } else {
          // ååˆ†ãªé•·ã•ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯è¿½åŠ ã—ã¦æ–°ã—ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é–‹å§‹
          processedTranscript.push(currentSegment);
          currentSegment = { ...segment };
        }
        
        // æœ€å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å‡¦ç†
        if (index === scaledTranscript.length - 1 && currentSegment) {
          processedTranscript.push(currentSegment);
        }
      });
      
      // å‡¦ç†æ¸ˆã¿ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰SRTã‚’ç”Ÿæˆ
      processedTranscript.forEach((segment, index) => {
        const startTime = formatSRTTime(segment.startTime)
        const endTime = formatSRTTime(segment.endTime)
        srtContent += `${index + 1}\n${startTime} --> ${endTime}\n${segment.text}\n\n`
        console.log(`å­—å¹•ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ${index + 1}: ${startTime} --> ${endTime} | ${segment.text}`)
      })
    } else {
      // éŸ³å£°å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¨ä½“ã®å­—å¹•ã¨ã—ã¦ä½¿ç”¨
      console.log('transcriptãŒç©ºã®ãŸã‚ã€audioInputã‹ã‚‰å­—å¹•ã‚’ç”Ÿæˆ')
      const text = typeof audioInput === 'string' ? audioInput : (audioInput as any).source
      
      // æ—¥æœ¬èªã®å ´åˆã¯æ–‡å­—å˜ä½ã€è‹±èªã®å ´åˆã¯å˜èªå˜ä½ã§åˆ†å‰²
      const isJapanese = /[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]/.test(text);
      console.log('ãƒ†ã‚­ã‚¹ãƒˆè¨€èªåˆ¤å®š:', isJapanese ? 'æ—¥æœ¬èª' : 'è‹±èª');
      
      if (isJapanese) {
        // æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆï¼šå¥èª­ç‚¹ã§åˆ†å‰²
        const sentences = text.split(/[ã€‚ï¼ï¼Ÿ]/).filter((s: string) => s.trim());
        const segmentCount = Math.min(sentences.length, 30); // æœ€å¤§30ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
        const segmentDuration = audioDuration / Math.max(segmentCount, 1);
        
        sentences.forEach((sentence: string, index: number) => {
          if (index < 30 && sentence.trim()) { // æœ€å¤§30ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¾ã§
            const startTime = index * segmentDuration;
            const endTime = (index + 1) * segmentDuration;
            srtContent += `${index + 1}\n${formatSRTTime(startTime)} --> ${formatSRTTime(endTime)}\n${sentence.trim()}\n\n`;
          }
        });
      } else {
        // è‹±èªãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆï¼šå˜èªã§åˆ†å‰²
        const words = text.split(' ');
        const wordsPerSegment = Math.ceil(words.length / 20);
        const segmentDuration = audioDuration / 20;
        
        for (let i = 0; i < 20; i++) {
          const startTime = i * segmentDuration;
          const endTime = (i + 1) * segmentDuration;
          const segmentWords = words.slice(i * wordsPerSegment, (i + 1) * wordsPerSegment);
          const segmentText = segmentWords.join(' ');
          
          if (segmentText.trim()) {
            srtContent += `${i + 1}\n${formatSRTTime(startTime)} --> ${formatSRTTime(endTime)}\n${segmentText}\n\n`;
          }
        }
      }
    }
    
    await fs.promises.writeFile(subtitlePath, srtContent, 'utf-8')
    console.log('Subtitle file created:', subtitlePath)
    
    // èƒŒæ™¯ç”»åƒã‚’ç”Ÿæˆ
    const { createCanvas } = require('canvas')
    const canvas = createCanvas(settings.resolution?.width || 1920, settings.resolution?.height || 1080)
    const ctx = canvas.getContext('2d')
    
    // ã‚·ãƒ³ãƒ—ãƒ«ãªèƒŒæ™¯ï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    const gradient = ctx.createLinearGradient(0, 0, 0, canvas.height)
    gradient.addColorStop(0, '#2c3e50')
    gradient.addColorStop(1, '#34495e')
    ctx.fillStyle = gradient
    ctx.fillRect(0, 0, canvas.width, canvas.height)
    
    // èƒŒæ™¯ç´ æã®æº–å‚™
    let backgroundInput = ''
    let inputOptions: string[] = []
    
    if (timeline && timeline.timeline && timeline.timeline.length > 0) {
      // å‹•ç”»ç´ æãŒã‚ã‚‹å ´åˆã¯æœ€åˆã®å‹•ç”»ã‚’ä½¿ç”¨
      const firstVideoAsset = timeline.timeline.find((item: any) => item.asset && item.asset.url)
      if (firstVideoAsset && firstVideoAsset.asset.url) {
        backgroundInput = firstVideoAsset.asset.url
        console.log('Using video asset as background:', backgroundInput)
      } else {
        // å‹•ç”»ç´ æãŒãªã„å ´åˆã¯é™æ­¢ç”»åƒã‚’ä½œæˆ
        const backgroundPath = path.join(tempDir, 'background.png')
        const buffer = canvas.toBuffer('image/png')
        await fs.promises.writeFile(backgroundPath, buffer)
        backgroundInput = backgroundPath
        inputOptions = ['-loop 1']
        console.log('Background image created:', backgroundPath)
      }
    } else {
      // timelineãŒãªã„å ´åˆã¯é™æ­¢ç”»åƒã‚’ä½œæˆ
      const backgroundPath = path.join(tempDir, 'background.png')
      const buffer = canvas.toBuffer('image/png')
      await fs.promises.writeFile(backgroundPath, buffer)
      backgroundInput = backgroundPath
      inputOptions = ['-loop 1']
      console.log('Background image created:', backgroundPath)
    }
    
    // FFmpegã§å‹•ç”»ç”Ÿæˆï¼ˆéŸ³å£° + èƒŒæ™¯ + å­—å¹•ï¼‰
    return new Promise((resolve, reject) => {
      let ffmpegCommand = ffmpeg()
        .input(backgroundInput)
      
      if (inputOptions.length > 0) {
        ffmpegCommand.inputOptions(inputOptions)
      }
      
      // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ 
      if (audioPath && fs.existsSync(audioPath)) {
        console.log('Adding audio track:', audioPath)
        ffmpegCommand.input(audioPath)
      }
      
      // å­—å¹•ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’è¿½åŠ ï¼ˆforce_styleã‚’å‰Šé™¤ã—ã¦SRTã®æ™‚é–“æƒ…å ±ã‚’å°Šé‡ï¼‰
      const subtitleFilter = `subtitles=${subtitlePath.replace(/\\/g, '\\\\').replace(/:/g, '\\:')}`
      
      // å‹•ç”»ç´ æã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¨ãã†ã§ãªã„å ´åˆã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’åˆ†ã‘ã‚‹
      const videoFilters = [`scale=${settings.resolution?.width || 1920}:${settings.resolution?.height || 1080}`]
      
      // é™æ­¢ç”»åƒã®å ´åˆã®ã¿å‹•çš„åŠ¹æœã‚’è¿½åŠ 
      if (inputOptions.includes('-loop 1')) {
        videoFilters.push(
          // å‹•çš„ãªè¦–è¦šåŠ¹æœã‚’è¿½åŠ 
          'zoompan=z=\'1+0.0005*on\':d=1:s=1920x1080',
          // è‰²ç›¸ã®å¾®å¦™ãªå¤‰åŒ–
          'hue=h=sin(2*PI*t/15)*20',
          // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³åŠ¹æœ
          'fade=in:0:30'
        )
      }
      
      // å­—å¹•ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯å¸¸ã«è¿½åŠ 
      videoFilters.push(subtitleFilter)
      
      ffmpegCommand.videoFilters(videoFilters)
        .videoCodec('libx264')
        .fps(settings.fps || 30)
        .outputOptions(['-pix_fmt yuv420p', '-preset fast', '-crf 28'])
      
      // éŸ³å£°ãŒã‚ã‚‹å ´åˆã¯éŸ³å£°ã‚’çµ±åˆ
      if (audioPath && fs.existsSync(audioPath)) {
        console.log('Integrating audio with video')
        ffmpegCommand
          .audioCodec('aac')
          .audioBitrate('128k')
          .outputOptions(['-t', audioDuration.toString()])
      } else {
        console.log('No audio file, creating silent video')
        ffmpegCommand.outputOptions(['-t', audioDuration.toString()])
      }
      
      ffmpegCommand
        .output(finalOutputPath)
        .on('start', (commandLine) => {
          console.log('FFmpeg command:', commandLine)
          console.log('å‡ºåŠ›å…ˆ:', finalOutputPath)
        })
        .on('progress', (progress) => {
          console.log('Processing: ' + progress.percent + '% done')
        })
        .on('end', () => {
          console.log('Subtitle video generation completed at:', finalOutputPath)
          // ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèª
          if (fs.existsSync(finalOutputPath)) {
            const stats = fs.statSync(finalOutputPath)
            console.log('ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«:', {
              path: finalOutputPath,
              size: stats.size,
              sizeInMB: (stats.size / 1024 / 1024).toFixed(2) + ' MB'
            })
          } else {
            console.error('å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ:', finalOutputPath)
          }
          resolve(finalOutputPath)
        })
        .on('error', (err) => {
          console.error('FFmpeg error:', err)
          reject(err)
        })
        .run()
    })
  } catch (error) {
    console.error('Subtitle video generation error:', error)
    throw error
  }
}

// SRTæ™‚é–“ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé–¢æ•°
function formatSRTTime(seconds: number): string {
  const hours = Math.floor(seconds / 3600)
  const minutes = Math.floor((seconds % 3600) / 60)
  const secs = Math.floor(seconds % 60)
  const milliseconds = Math.floor((seconds % 1) * 1000)
  
  return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')},${milliseconds.toString().padStart(3, '0')}`
}

// å‹•çš„ãªå‹•ç”»ç”Ÿæˆé–¢æ•°
async function generateSimpleVideo({
  audioInput,
  settings,
  outputPath,
  tempDir,
  timeline
}: {
  audioInput: any
  settings: any
  outputPath: string
  tempDir: string
  timeline?: any[]
}) {
  console.log('Generating animated video with Canvas and FFmpeg')
  
  try {
    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    const audioPath = await processAudioFile(audioInput, tempDir)
    console.log('Subtitle video - Processed audio path:', audioPath)
    
    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if (audioPath && fs.existsSync(audioPath)) {
      const stats = await fs.promises.stat(audioPath)
      console.log('Subtitle video - Audio file size:', stats.size, 'bytes')
    } else {
      console.log('Subtitle video - No audio file available or file does not exist')
     }
    
    // Canvas ã§é­…åŠ›çš„ãªèƒŒæ™¯ç”»åƒã‚’ç”Ÿæˆ
    const { createCanvas } = require('canvas')
    const canvas = createCanvas(settings.resolution?.width || 1920, settings.resolution?.height || 1080)
    const ctx = canvas.getContext('2d')
    
    // å‹•çš„ãªèƒŒæ™¯ã®ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    const gradient = ctx.createLinearGradient(0, 0, canvas.width, canvas.height)
    gradient.addColorStop(0, '#ff6b6b')
    gradient.addColorStop(0.3, '#4ecdc4')
    gradient.addColorStop(0.6, '#45b7d1')
    gradient.addColorStop(1, '#96ceb4')
    ctx.fillStyle = gradient
    ctx.fillRect(0, 0, canvas.width, canvas.height)
    
    // éŸ³å£°æ³¢å½¢é¢¨ã®è£…é£¾
    ctx.strokeStyle = 'rgba(255, 255, 255, 0.4)'
    ctx.lineWidth = 4
    for (let i = 0; i < 30; i++) {
      const x = (canvas.width / 30) * i + 30
      const baseHeight = canvas.height * 0.7
      const waveHeight = Math.sin(i * 0.3) * 60 + 80
      
      ctx.beginPath()
      ctx.moveTo(x, baseHeight)
      ctx.lineTo(x, baseHeight - waveHeight)
      ctx.stroke()
    }
    
    // ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒˆãƒ«
    ctx.shadowColor = '#ffffff'
    ctx.shadowBlur = 10
    ctx.fillStyle = 'white'
    ctx.font = 'bold 64px Arial'
    ctx.textAlign = 'center'
    ctx.textBaseline = 'middle'
    ctx.fillText('éŸ³å£°ã‹ã‚‰å‹•ç”»ç”Ÿæˆ', canvas.width / 2, canvas.height / 2 - 50)
    
    // éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯æƒ…å ±
    ctx.shadowBlur = 0
    if (audioPath) {
      ctx.fillStyle = 'rgba(251, 191, 36, 0.8)'
      ctx.font = '32px Arial'
      ctx.textAlign = 'center'
      ctx.fillText('ğŸµ éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ä»˜ã', canvas.width / 2, canvas.height / 2 + 50)
    } else {
      ctx.fillStyle = 'rgba(148, 163, 184, 0.8)'
      ctx.font = '24px Arial'
      ctx.textAlign = 'center'
      ctx.fillText('éŸ³å£°ãªã—', canvas.width / 2, canvas.height / 2 + 50)
    }
    
    // ç”Ÿæˆæ™‚åˆ»
    const now = new Date()
    ctx.fillStyle = 'rgba(226, 232, 240, 0.6)'
    ctx.font = '20px Arial'
    ctx.textAlign = 'right'
    ctx.fillText(`ç”Ÿæˆæ™‚åˆ»: ${now.toLocaleString('ja-JP')}`, canvas.width - 50, 50)
    
    // é™æ­¢ç”»ã‚’ä¿å­˜
    const imagePath = path.join(tempDir, 'background.png')
    const buffer = canvas.toBuffer('image/png')
    await fs.promises.writeFile(imagePath, buffer)
    
    console.log('Background image created:', imagePath)
    
    // ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ™ãƒ¼ã‚¹ã®å‹•ç”»ç”Ÿæˆ
    if (timeline && timeline.length > 0) {
      console.log('ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ™ãƒ¼ã‚¹ã®å‹•ç”»ç”Ÿæˆé–‹å§‹')
      return await generateTimelineBasedVideo({
        timeline,
        audioPath,
        outputPath,
        settings,
        tempDir
      })
    }
    
    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é™æ­¢ç”»ãƒ™ãƒ¼ã‚¹ã®å‹•ç”»ç”Ÿæˆ
    return new Promise((resolve, reject) => {
      const ffmpegCommand = ffmpeg()
        .input(imagePath)
        .inputOptions(['-loop 1', '-t', (settings.duration || 60).toString()])
        .videoCodec('libx264')
        .fps(settings.fps || 30)
        .videoFilters([
          // ã‚†ã£ãã‚Šã¨ã—ãŸã‚ºãƒ¼ãƒ ã‚¤ãƒ³åŠ¹æœ
          'zoompan=z=\'1+0.001*on\':d=1:s=1920x1080',
          // è‰²ç›¸ã®å¾®å¦™ãªå¤‰åŒ–
          'hue=h=sin(2*PI*t/10)*30',
          // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³åŠ¹æœ
          'fade=in:0:30'
        ])
        .outputOptions([
          '-pix_fmt yuv420p',
          '-preset fast',
          '-crf 28'
        ])
      
      // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
      if (audioPath && fs.existsSync(audioPath)) {
        console.log('Adding audio track:', audioPath)
        ffmpegCommand
          .input(audioPath)
          .audioCodec('aac')
          .outputOptions([
            '-map 0:v:0',  // æœ€åˆã®å…¥åŠ›ã®å‹•ç”»ã‚¹ãƒˆãƒªãƒ¼ãƒ 
            '-map 1:a:0',  // äºŒç•ªç›®ã®å…¥åŠ›ã®éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ 
            '-shortest'    // çŸ­ã„æ–¹ã®é•·ã•ã«åˆã‚ã›ã‚‹
          ])
      } else {
        console.log('No audio track provided, generating silent video')
      }
      
      ffmpegCommand
        .output(outputPath)
        .on('start', (commandLine) => {
          console.log('FFmpeg command:', commandLine)
        })
        .on('progress', (progress) => {
          console.log('Processing: ' + progress.percent + '% done')
        })
        .on('end', () => {
          console.log('Video generation completed successfully')
          resolve(outputPath)
        })
        .on('error', (err) => {
          console.error('FFmpeg error:', err)
          reject(err)
        })
        .run()
    })
  } catch (error) {
    console.error('Canvas error:', error)
    throw error
  }
}

export async function POST(request: NextRequest) {
  try {
    console.log('å‹•ç”»ç”ŸæˆAPIé–‹å§‹:', new Date().toISOString())
    
    const body = await request.json() as VideoGenerationRequest
    console.log('ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£å—ä¿¡:', JSON.stringify(body, null, 2))
    const { audioInput, settings, transcript, customAssets } = body
    
    if (!audioInput || !settings) {
      return NextResponse.json(
        { error: 'å¿…è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™', code: 'INVALID_REQUEST' },
        { status: 400 }
      )
    }

    // 1. å¤ã„ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆ1æ™‚é–“ä»¥ä¸Šå¤ã„ã‚‚ã®ï¼‰
    try {
      const tmpDir = os.tmpdir()
      const allDirs = await fs.promises.readdir(tmpDir)
      const videoDirs = allDirs.filter(dir => dir.startsWith('video-generation-'))
      
      for (const dir of videoDirs) {
        const dirPath = path.join(tmpDir, dir)
        try {
          const stats = await fs.promises.stat(dirPath)
          const ageInHours = (Date.now() - stats.mtime.getTime()) / (1000 * 60 * 60)
          
          if (ageInHours > 1) { // 1æ™‚é–“ä»¥ä¸Šå¤ã„
            await fs.promises.rm(dirPath, { recursive: true, force: true })
            console.log('Cleaned up old directory:', dirPath)
          }
        } catch (error) {
          console.log('Failed to clean up directory:', dirPath, error)
        }
      }
    } catch (error) {
      console.log('Directory cleanup failed:', error)
    }

    // 2. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
    const tempDir = await fs.promises.mkdtemp(path.join(os.tmpdir(), 'video-generation-'))
    console.log('Temporary directory created:', tempDir)
    
    const audioPath = await processAudioFile(audioInput, tempDir)
    console.log('Audio processing completed:', audioPath)
    
    // å®Ÿéš›ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’å–å¾—
    let audioDuration: number = settings.duration // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    if (audioPath) {
      try {
        audioDuration = await getAudioDuration(audioPath)
        console.log('Using actual audio duration:', audioDuration, 'seconds')
      } catch (error) {
        console.error('Failed to get audio duration, using default:', settings.duration)
        audioDuration = settings.duration
      }
    }

    // 2. æ–‡å­—èµ·ã“ã—ã®å‡¦ç†
    let processedTranscript: TranscriptSegment[] = transcript || [
      { text: 'ã‚µãƒ³ãƒ—ãƒ«æ–‡å­—èµ·ã“ã—', startTime: 0, endTime: audioDuration }
    ]

    // 3. æ–‡å­—èµ·ã“ã—çµæœã‚’åˆ†æã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã‚·ãƒ¼ãƒ³ã‚’æŠ½å‡º
    console.log('æ–‡å­—èµ·ã“ã—åˆ†æé–‹å§‹')
    const analysisResult = await analyzeTranscriptForKeywords(processedTranscript)
    console.log('åˆ†æçµæœ:', analysisResult)

    // 4. æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ç´ æã‚’æ¤œç´¢
    console.log('ç´ ææ¤œç´¢é–‹å§‹')
    let videoAssets: VideoAsset[] = customAssets || []
    
    if (analysisResult.scenes.length > 0) {
      const searchedAssets = await searchMediaAssets(analysisResult.keywords, analysisResult.scenes)
      videoAssets = [...videoAssets, ...searchedAssets]
    }
    
    console.log('ç´ æå–å¾—å®Œäº†:', videoAssets.length, 'å€‹')
    
    // 5. ç´ æã‚’ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«é…ç½®
    console.log('ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³é…ç½®é–‹å§‹')
    const timelineResult = await arrangeAssetsOnTimeline(videoAssets, audioDuration)
    console.log('ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³é…ç½®å®Œäº†:', timelineResult.timeline.length, 'å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ')

    // 5. å‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰
    const metadata = {
      title: 'ãƒ†ã‚¹ãƒˆå‹•ç”»',
      description: 'ãƒ†ã‚¹ãƒˆç”¨ã®å‹•ç”»ã§ã™'
    }
    
    // 6. å®Ÿéš›ã®å‹•ç”»ç”Ÿæˆ
    console.log('å‹•ç”»ç”Ÿæˆé–‹å§‹:', new Date().toISOString())
    
    let result: VideoGenerationResult
    let outputPath: string
    let fileSize: number
    
    // å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºä¿
    const outputDir = path.join(process.cwd(), 'public', 'output')
    if (!fs.existsSync(outputDir)) {
      await fs.promises.mkdir(outputDir, { recursive: true })
    }
    
    // ã‚¸ãƒ§ãƒ–IDã‚’ç”Ÿæˆ
    const jobId = `job-${Date.now()}-${Math.random().toString(36).substring(2)}`
    outputPath = path.join(outputDir, `${jobId}.mp4`)
    console.log('Output path:', outputPath)
    
    console.log('processAudioFileçµæœ:', { audioPath, exists: audioPath ? fs.existsSync(audioPath) : false })
    
    // æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚’æ”¹å–„
    let transcriptWithTimestamps: any[] = []
    
    // æ—¢å­˜ã®transcriptãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
    if (processedTranscript && processedTranscript.length > 0) {
      console.log('æ—¢å­˜ã®æ–‡å­—èµ·ã“ã—ã‚’ä½¿ç”¨:', processedTranscript.length, 'å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ')
      transcriptWithTimestamps = processedTranscript
    } else if (audioPath && fs.existsSync(audioPath)) {
      try {
        console.log('éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹...', audioPath)
        transcriptWithTimestamps = await transcribeAudioWithTimestamps(audioPath)
        console.log('æ–‡å­—èµ·ã“ã—å®Œäº†:', transcriptWithTimestamps.length, 'å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ')
      } catch (error) {
        console.error('æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼:', error)
        // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å­—å¹•ã‚’ä½œæˆ
        transcriptWithTimestamps = [{
          text: 'Generated Video',
          startTime: 0,
          endTime: audioDuration
        }]
      }
    } else {
      // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
      console.log('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å­—å¹•ã‚’ä½œæˆ')
      transcriptWithTimestamps = [{
        text: 'Generated Video Content',
        startTime: 0,
        endTime: audioDuration
      }]
    }
    
    // éŸ³å£°ã‚’å­—å¹•ã¨ã—ã¦è¡¨ç¤ºã™ã‚‹å‹•ç”»ç”Ÿæˆ
    const audioText = typeof audioInput === 'string' ? audioInput : (typeof audioInput.source === 'string' ? audioInput.source : '')
    const tempVideoPath = await generateSubtitleVideo({
      audioPath: audioPath || '',
      audioInput: audioText,
      transcript: transcriptWithTimestamps.length > 0 ? transcriptWithTimestamps : (processedTranscript || []),
      settings,
      tempDir,
      timeline: timelineResult,
      audioDuration
    })
    
    // generateSubtitleVideoã¯ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹ã®ã§ã€
    // æ­£ã—ã„å‡ºåŠ›ãƒ‘ã‚¹ã«ç›´æ¥ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«å¤‰æ›´
    console.log('å‹•ç”»ç”Ÿæˆã‚’æ­£ã—ã„å‡ºåŠ›ãƒ‘ã‚¹ã§å®Ÿè¡Œ:', outputPath)
    
    // ä¸€æ™‚å‹•ç”»ãƒ‘ã‚¹ã§ã¯ãªãã€ç›´æ¥æœ€çµ‚å‡ºåŠ›ãƒ‘ã‚¹ã‚’ä½¿ç”¨
    const finalVideoPath = await generateSubtitleVideo({
      audioPath: audioPath || '',
      audioInput: audioText,
      transcript: transcriptWithTimestamps.length > 0 ? transcriptWithTimestamps : (processedTranscript || []),
      settings,
      tempDir,
      timeline: timelineResult,
      audioDuration,
      outputPath: outputPath  // ç›´æ¥å‡ºåŠ›ãƒ‘ã‚¹ã‚’æŒ‡å®š
    })
    
    console.log('å‹•ç”»ç”Ÿæˆå®Œäº†ã€æœ€çµ‚ãƒ‘ã‚¹:', finalVideoPath)
    
    // å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚ŒãŸã‹ç¢ºèª
    if (fs.existsSync(finalVideoPath)) {
      const stats = await fs.promises.stat(finalVideoPath)
      fileSize = stats.size
      console.log('Video file generated successfully:', {
        path: finalVideoPath,
        size: fileSize,
        sizeInMB: (fileSize / 1024 / 1024).toFixed(2) + ' MB'
      })
      
      // public/outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ã‚‚ç¢ºèª
      const outputDir = path.dirname(finalVideoPath)
      const outputFiles = fs.readdirSync(outputDir)
      console.log('å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹:', outputFiles)
      
      // outputPathã‚’æ›´æ–°
      outputPath = finalVideoPath
    } else {
      console.error('æœ€çµ‚çš„ãªå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:', finalVideoPath)
      throw new Error('å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ')
    }
    
    // å…¬é–‹ç”¨ãƒ‘ã‚¹ã‚’ç”Ÿæˆï¼ˆAPIãƒ«ãƒ¼ãƒˆçµŒç”±ï¼‰
    const publicVideoPath = `/api/output/${jobId}.mp4`
    
    result = {
      videoUrl: publicVideoPath,
      thumbnailUrl: videoAssets[0]?.url || 'https://via.placeholder.com/1280x720/0066cc/ffffff?text=Generated+Video',
      duration: audioDuration,
      format: settings.format,
      size: fileSize,
      jobId: jobId
    }
    
    console.log('Video generation completed:', result)
    
    console.log('å®Ÿéš›ã®å‹•ç”»ç”Ÿæˆå®Œäº†:', {
      title: metadata.title,
      assets: videoAssets.length,
      outputPath,
      fileSize: `${(fileSize / 1024 / 1024).toFixed(1)}MB`
    })
    
    console.log('å‹•ç”»ç”ŸæˆAPIå®Œäº†:', new Date().toISOString())
    
    return NextResponse.json({
      success: true,
      result,
      title: metadata.title,
      description: metadata.description,
      scenesCount: analysisResult.scenes.length,
      assetsUsed: videoAssets.length,
      jobId: result.jobId
    }, { status: 200 })
    
  } catch (error: any) {
    console.error('å‹•ç”»ç”Ÿæˆã‚¨ãƒ©ãƒ¼è©³ç´°:', {
      message: error.message,
      stack: error.stack,
      name: error.name,
      cause: error.cause
    })
    
    return NextResponse.json(
      {
        error: `å‹•ç”»ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: ${error.message}`,
        code: 'VIDEO_GENERATION_FAILED',
        details: error.stack,
        errorName: error.name
      },
      { status: 500 }
    )
  }
}

// å‹•ç”»ç”Ÿæˆã®é€²è¡ŒçŠ¶æ³ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®GETã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
export async function GET(request: NextRequest) {
  const { searchParams } = new URL(request.url)
  const jobId = searchParams.get('jobId')
  
  if (!jobId) {
    return NextResponse.json(
      { error: 'ã‚¸ãƒ§ãƒ–IDãŒå¿…è¦ã§ã™', code: 'INVALID_REQUEST' },
      { status: 400 }
    )
  }
  
  // å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚¸ãƒ§ãƒ–ã®é€²è¡ŒçŠ¶æ³ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
  return NextResponse.json({
    jobId,
    status: 'completed', // 'pending' | 'processing' | 'completed' | 'failed'
    progress: 100,
    message: 'å‹•ç”»ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ'
  })
}
